{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20079e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4173 records\n",
      "Unique sheets: 12\n",
      "Unique events: 49\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd #type: ignore\n",
    "import numpy as np\n",
    "\n",
    "# Load the ordered data\n",
    "df = pd.read_csv('processed_data/ordered_times.csv')\n",
    "\n",
    "# Define the order lists (same as in data_wrangler.ipynb)\n",
    "sheet_order = [\n",
    "    #'CMS All Time Top 10',\n",
    "    #'CMS Axelrood Pool Records',\n",
    "    #'CMS Frosh Swimming & Diving Records',\n",
    "    #'Development of Team Records (October 2001 to March 2025)', \n",
    "    'CMS at UCSD',\n",
    "    'CMS at Cal Baptist Distance Meet',\n",
    "    'CMS at PP',\n",
    "    'CMS at PP Combined', \n",
    "    'CMS SCIAC Champions',\n",
    "    'SCIAC All Time Top 10 Performers',\n",
    "    'SCIAC Records',\n",
    "    'NCAA TOP 20'\n",
    "]\n",
    "\n",
    "sex_order = ['Athena', 'Stag', 'Women', 'Men']\n",
    "\n",
    "event_order = [\n",
    "    # FREE\n",
    "    '50 FREE', '100 FREE', '200 FREE', '500 FREE', '1000 FREE', '1650 FREE',\n",
    "    # BACK\n",
    "    '50 BACK', '100 BACK', '200 BACK', '300 BACK',\n",
    "    # BREAST\n",
    "    '50 BREAST', '100 BREAST', '200 BREAST', '300 BREAST',\n",
    "    # FLY\n",
    "    '100 FLY', '200 FLY', '300 FLY',\n",
    "    # IM\n",
    "    '200 IM', '300 IM', '400 IM',\n",
    "    # DIVING (METER)\n",
    "    '1-METER (6 dives)', '1-METER (11 dives)', '1-METER',\n",
    "    '3-METER (6 dives)', '3-METER (11 dives)', '3-METER',\n",
    "    # RELAY\n",
    "    '200 FREE RELAY', '400 FREE RELAY', '500 FREE RELAY- (50-100-150-200)',\n",
    "    '800 FREE RELAY', '200 MEDLEY RELAY', '400 MEDLEY RELAY',\n",
    "    '500 MEDLEY RELAY - (200 BACK-150 BR-100 FL-50 FS)',\n",
    "    # Spl.\n",
    "    '50 FREE - RELAY Spl.', '50 FREE Spl.', '100 FREE - RELAY Spl.',\n",
    "    '100 FREE Spl.', '200 FREE - RELAY Spl.', '200 FREE Spl.',\n",
    "    '50 BACK - RELAY Spl.', '50 BACK Spl.', '50 BREAST - RELAY Spl.',\n",
    "    '50 BREAST Spl.', '100 BREAST - RELAY Spl.', '100 BREAST Spl.',\n",
    "    '50 FLY - RELAY Spl.', '50 FLY Spl.', '100 FLY - RELAY Spl.', '100 FLY Spl.'\n",
    "]\n",
    "\n",
    "print(f\"Loaded {len(df)} records\")\n",
    "print(f\"Unique sheets: {df['SHEET'].nunique()}\")\n",
    "print(f\"Unique events: {df['EVENT'].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "01a7e94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple generator created!\n"
     ]
    }
   ],
   "source": [
    "class SimpleSwimTableGenerator:\n",
    "    def __init__(self, df, sheet_order, sex_order, event_order):\n",
    "        self.df = df\n",
    "        self.sheet_order = sheet_order\n",
    "        self.sex_order = sex_order\n",
    "        self.event_order = event_order\n",
    "        \n",
    "        # Override system for special cases\n",
    "        self.overrides = {\n",
    "            'RELAY': {'layout': 'single_column', 'max_entries': None},\n",
    "            'Spl.': {'layout': 'single_column', 'max_entries': None},\n",
    "            'METER': {'layout': 'single_column', 'max_entries': None},\n",
    "            'CMS All Time Top 10': {'max_entries': 10},\n",
    "            'CMS at PP': {'max_entries': 10}\n",
    "        }\n",
    "    \n",
    "    def time_to_seconds(self, time_str):\n",
    "        \"\"\"Convert time string to seconds for sorting\"\"\"\n",
    "        if pd.isna(time_str):\n",
    "            return float('inf')\n",
    "        try:\n",
    "            time_str = str(time_str).strip()\n",
    "            if ':' in time_str:\n",
    "                parts = time_str.split(':')\n",
    "                minutes = float(parts[0])\n",
    "                seconds = float(parts[1])\n",
    "                return minutes * 60 + seconds\n",
    "            else:\n",
    "                return float(time_str)\n",
    "        except (ValueError, AttributeError):\n",
    "            return float('inf')\n",
    "    \n",
    "    def get_table_columns(self, data):\n",
    "        \"\"\"Determine which columns to include in the table\"\"\"\n",
    "        available_cols = []\n",
    "        \n",
    "        # Clean column names by stripping whitespace\n",
    "        data_columns = [col.strip() for col in data.columns]\n",
    "        data.columns = data_columns\n",
    "        \n",
    "        # Check each column and include it if it has data\n",
    "        for col in ['TIME', 'NAME', 'YEAR', 'TEAM', 'RANK', 'SITE', 'MEET', 'CONTEXT', 'DATE']:\n",
    "            if col in data.columns:\n",
    "                # Check if column has any non-null, non-empty values\n",
    "                non_null_count = data[col].notna().sum()\n",
    "                non_empty_count = (data[col].astype(str).str.strip() != '').sum()\n",
    "                \n",
    "                if non_null_count > 0 and non_empty_count > 0:\n",
    "                    available_cols.append(col)\n",
    "        \n",
    "        return available_cols\n",
    "    \n",
    "    def get_column_widths(self, columns):\n",
    "        \"\"\"Get appropriate column widths based on column types - optimized for wider tables\"\"\"\n",
    "        width_map = {\n",
    "            'TIME': '1.8cm',\n",
    "            'NAME': '2.8cm', \n",
    "            'YEAR': '1.2cm',\n",
    "            'TEAM': '1.4cm',\n",
    "            'RANK': '0.8cm',\n",
    "            'SITE': '1.4cm',\n",
    "            'MEET': '1.4cm',\n",
    "            'CONTEXT': '2.0cm',\n",
    "            'DATE': '1.2cm'\n",
    "        }\n",
    "        return [width_map.get(col, '1.5cm') for col in columns]\n",
    "    \n",
    "    def get_column_headers(self, columns):\n",
    "        \"\"\"Get LaTeX headers for columns\"\"\"\n",
    "        header_map = {\n",
    "            'TIME': '\\\\textbf{TIME}',\n",
    "            'NAME': '\\\\textbf{NAME}',\n",
    "            'YEAR': '\\\\textbf{YEAR}',\n",
    "            'TEAM': '\\\\textbf{TEAM}',\n",
    "            'RANK': '\\\\textbf{RANK}',\n",
    "            'SITE': '\\\\textbf{SITE}',\n",
    "            'MEET': '\\\\textbf{MEET}',\n",
    "            'CONTEXT': '\\\\textbf{CONTEXT}',\n",
    "            'DATE': '\\\\textbf{DATE}'\n",
    "        }\n",
    "        return [header_map.get(col, f'\\\\textbf{{{col}}}') for col in columns]\n",
    "    \n",
    "    def estimate_table_height(self, num_entries, num_columns):\n",
    "        \"\"\"Estimate table height in lines for page planning\"\"\"\n",
    "        # Base height: title (1) + header (1) + bottom border (1) = 3 lines\n",
    "        # Each data row = 1 line\n",
    "        # Add some padding\n",
    "        return 3 + num_entries + 1\n",
    "    \n",
    "    def should_use_single_column(self, event_name, num_entries):\n",
    "        \"\"\"Determine if event should use single column layout\"\"\"\n",
    "        # Check overrides first\n",
    "        for key, config in self.overrides.items():\n",
    "            if key in event_name:\n",
    "                if 'layout' in config and config['layout'] == 'single_column':\n",
    "                    return True\n",
    "        \n",
    "        # Default logic - be more conservative about single column\n",
    "        if 'RELAY' in event_name or 'Spl.' in event_name or 'METER' in event_name:\n",
    "            return True\n",
    "        if num_entries > 20:  # Increased threshold\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def group_events_for_layout(self, events_data):\n",
    "        \"\"\"Group events into efficient grid layout - 2 columns x 3 rows per page\"\"\"\n",
    "        groups = []\n",
    "        i = 0\n",
    "        \n",
    "        while i < len(events_data):\n",
    "            # Create a row with up to 2 events\n",
    "            row_events = []\n",
    "            \n",
    "            # First event in row\n",
    "            if i < len(events_data):\n",
    "                event_name, event_data = events_data[i]\n",
    "                row_events.append((event_name, event_data))\n",
    "                i += 1\n",
    "            \n",
    "            # Second event in row (if available and not single column)\n",
    "            if i < len(events_data):\n",
    "                next_event_name, next_event_data = events_data[i]\n",
    "                if not self.should_use_single_column(next_event_name, len(next_event_data)):\n",
    "                    row_events.append((next_event_name, next_event_data))\n",
    "                    i += 1\n",
    "            \n",
    "            groups.append(row_events)\n",
    "        \n",
    "        return groups\n",
    "    \n",
    "    def generate_table_latex(self, event_name, data):\n",
    "        \"\"\"Generate LaTeX for a single table using direct tabular environment\"\"\"\n",
    "        # Sort by time if TIME column exists\n",
    "        if 'TIME' in data.columns:\n",
    "            data = data.copy()\n",
    "            data['time_seconds'] = data['TIME'].apply(self.time_to_seconds)\n",
    "            data = data.sort_values('time_seconds').drop('time_seconds', axis=1)\n",
    "            data = data.reset_index(drop=True)\n",
    "        \n",
    "        # Apply max entries override\n",
    "        max_entries = None\n",
    "        for key, config in self.overrides.items():\n",
    "            if key in event_name or key in data['SHEET'].iloc[0] if len(data) > 0 else False:\n",
    "                if 'max_entries' in config:\n",
    "                    max_entries = config['max_entries']\n",
    "                    break\n",
    "        \n",
    "        if max_entries and len(data) > max_entries:\n",
    "            data = data.head(max_entries)\n",
    "        \n",
    "        # Get columns to include\n",
    "        columns = self.get_table_columns(data)\n",
    "        if not columns:\n",
    "            return f\"\\\\textbf{{{event_name}}}\\\\\\\\[0.1cm]\\\\textit{{No data available}}\"\n",
    "        \n",
    "        # Get column widths and headers\n",
    "        widths = self.get_column_widths(columns)\n",
    "        headers = self.get_column_headers(columns)\n",
    "        \n",
    "        # Build tabular specification\n",
    "        col_spec = '@{}' + 'p{' + '}p{'.join(widths) + '}@{}'\n",
    "        \n",
    "        # Generate table rows with better formatting for manual editing\n",
    "        rows = []\n",
    "        for _, row in data.iterrows():\n",
    "            row_data = []\n",
    "            for col in columns:\n",
    "                value = str(row[col]) if pd.notna(row[col]) else \"\"\n",
    "                # Escape special LaTeX characters\n",
    "                value = value.replace('&', '\\\\&').replace('%', '\\\\%').replace('$', '\\\\$')\n",
    "                row_data.append(value)\n",
    "            rows.append(\"    \" + \" & \".join(row_data) + \" \\\\\\\\\")\n",
    "        \n",
    "        table_content = \"\\n\".join(rows)\n",
    "        header_row = \"    \" + \" & \".join(headers) + \" \\\\\\\\\"\n",
    "        \n",
    "        # Build complete table with clear structure for manual editing\n",
    "        table_latex = f\"\"\"\\\\centering\n",
    "\\\\textbf{{{event_name}}}\\\\\\\\[0.1cm]\n",
    "\\\\begin{{tabular}}{{{col_spec}}}\n",
    "\\\\hline\n",
    "{header_row}\n",
    "\\\\hline\n",
    "{table_content}\n",
    "\\\\hline\n",
    "\\\\end{{tabular}}\"\"\"\n",
    "        \n",
    "        return table_latex\n",
    "    \n",
    "    def generate_section_latex(self, sheet_name, sex_name, events_data):\n",
    "        \"\"\"Generate complete LaTeX section optimized for manual editing\"\"\"\n",
    "        latex_parts = []\n",
    "        \n",
    "        # Escape ampersands in section titles\n",
    "        escaped_sheet_name = sheet_name.replace('&', '\\\\&')\n",
    "        escaped_sex_name = sex_name.replace('&', '\\\\&')\n",
    "        \n",
    "        # Add clear section markers for manual editing\n",
    "        latex_parts.append(f\"% ===== {escaped_sheet_name} - {escaped_sex_name} =====\")\n",
    "        latex_parts.append(f\"\\\\subsection{{{escaped_sheet_name}}}\")\n",
    "        latex_parts.append(f\"\\\\subsubsection{{{escaped_sex_name}}}\")\n",
    "        latex_parts.append(\"\")\n",
    "        \n",
    "        # Group events for layout\n",
    "        event_groups = self.group_events_for_layout(events_data)\n",
    "        \n",
    "        for i, group in enumerate(event_groups):\n",
    "            # Add table group comment for easy identification\n",
    "            if len(group) == 2:\n",
    "                event1_name, event2_name = group[0][0], group[1][0]\n",
    "                latex_parts.append(f\"% Table Group {i+1}: {event1_name} + {event2_name}\")\n",
    "            else:\n",
    "                event_name = group[0][0]\n",
    "                latex_parts.append(f\"% Table Group {i+1}: {event_name}\")\n",
    "            \n",
    "            if len(group) == 2:\n",
    "                # Two-column layout - optimized for page usage\n",
    "                event1_name, event1_data = group[0]\n",
    "                event2_name, event2_data = group[1]\n",
    "                \n",
    "                table1 = self.generate_table_latex(event1_name, event1_data)\n",
    "                table2 = self.generate_table_latex(event2_name, event2_data)\n",
    "                \n",
    "                latex_parts.append(\"\\\\begin{table}[H]\")\n",
    "                latex_parts.append(\"\\\\centering\")\n",
    "                latex_parts.append(\"\\\\begin{minipage}[t]{0.48\\\\textwidth}\")\n",
    "                latex_parts.append(table1)\n",
    "                latex_parts.append(\"\\\\end{minipage}\\\\hfill\")\n",
    "                latex_parts.append(\"\\\\begin{minipage}[t]{0.48\\\\textwidth}\")\n",
    "                latex_parts.append(table2)\n",
    "                latex_parts.append(\"\\\\end{minipage}\")\n",
    "                latex_parts.append(\"\\\\end{table}\")\n",
    "                latex_parts.append(\"\")\n",
    "            else:\n",
    "                # Single column layout - optimized width\n",
    "                event_name, event_data = group[0]\n",
    "                table = self.generate_table_latex(event_name, event_data)\n",
    "                \n",
    "                latex_parts.append(\"\\\\begin{table}[H]\")\n",
    "                latex_parts.append(\"\\\\centering\")\n",
    "                latex_parts.append(\"\\\\begin{minipage}[t]{0.6\\\\textwidth}\")\n",
    "                latex_parts.append(table)\n",
    "                latex_parts.append(\"\\\\end{minipage}\")\n",
    "                latex_parts.append(\"\\\\end{table}\")\n",
    "                latex_parts.append(\"\")\n",
    "        \n",
    "        # Add section end marker\n",
    "        latex_parts.append(f\"% ===== END {escaped_sheet_name} - {escaped_sex_name} =====\")\n",
    "        latex_parts.append(\"\")\n",
    "        \n",
    "        return \"\\n\".join(latex_parts)\n",
    "\n",
    "# Create the generator\n",
    "generator = SimpleSwimTableGenerator(df, sheet_order, sex_order, event_order)\n",
    "print(\"Simple generator created!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e15ca62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating complete LaTeX...\n",
      "Generated LaTeX saved to 'generated_latex.tex'\n",
      "Total length: 333984 characters\n",
      "Number of lines: 10550\n",
      "\n",
      "Preview (first 15 lines):\n",
      " 1: % ===== CMS MEDIA GUIDE - GENERATED LATEX =====\n",
      " 2: % This file contains all swimming and diving tables\n",
      " 3: % Optimized for manual editing and page layout\n",
      " 4: \n",
      " 5: % ===== SECTION SUMMARY =====\n",
      " 6: % 1. CMS All Time Top 10 - Athena\n",
      " 7: % 2. CMS All Time Top 10 - Stag\n",
      " 8: % 3. CMS Axelrood Pool Records - Women\n",
      " 9: % 4. CMS Axelrood Pool Records - Men\n",
      "10: % 5. CMS Frosh Swimming & Diving Records - Athena\n",
      "11: % 6. CMS Frosh Swimming & Diving Records - Stag\n",
      "12: % 7. Development of Team Records (October 2001 to March 2025) - Athena\n",
      "13: % 8. Development of Team Records (October 2001 to March 2025) - Stag\n",
      "14: % 9. CMS at UCSD - Athena\n",
      "15: % 10. CMS at UCSD - Stag\n",
      "... and 10536 more lines\n",
      "\n",
      "Checking for Development of Team Records section:\n",
      "Line 12: % 7. Development of Team Records (October 2001 to March 2025) - Athena\n",
      "Line 13: % 8. Development of Team Records (October 2001 to March 2025) - Stag\n",
      "Line 14: % 9. CMS at UCSD - Athena\n",
      "Line 15: % 10. CMS at UCSD - Stag\n",
      "Line 16: % 11. CMS at Cal Baptist Distance Meet - Athena\n",
      "Line 17: % 12. CMS at Cal Baptist Distance Meet - Stag\n",
      "Line 13: % 8. Development of Team Records (October 2001 to March 2025) - Stag\n",
      "Line 14: % 9. CMS at UCSD - Athena\n",
      "Line 15: % 10. CMS at UCSD - Stag\n",
      "Line 16: % 11. CMS at Cal Baptist Distance Meet - Athena\n",
      "Line 17: % 12. CMS at Cal Baptist Distance Meet - Stag\n",
      "Line 18: % 13. CMS at PP - Athena\n",
      "Line 2485: % ===== Development of Team Records (October 2001 to March 2025) - Athena =====\n",
      "Line 2486: \\subsection{Development of Team Records (October 2001 to March 2025)}\n",
      "Line 2487: \\subsubsection{Athena}\n",
      "Line 2488: \n",
      "Line 2489: % Table Group 1: 50 FREE + 100 FREE\n",
      "Line 2490: \\begin{table}[H]\n",
      "Line 2486: \\subsection{Development of Team Records (October 2001 to March 2025)}\n",
      "Line 2487: \\subsubsection{Athena}\n",
      "Line 2488: \n",
      "Line 2489: % Table Group 1: 50 FREE + 100 FREE\n",
      "Line 2490: \\begin{table}[H]\n",
      "Line 2491: \\centering\n",
      "Line 2930: % ===== END Development of Team Records (October 2001 to March 2025) - Athena =====\n",
      "Line 2931: \n",
      "Line 2932: \\newpage\n",
      "Line 2933: \n",
      "Line 2934: % ===== Development of Team Records (October 2001 to March 2025) - Stag =====\n",
      "Line 2935: \\subsection{Development of Team Records (October 2001 to March 2025)}\n",
      "Line 2934: % ===== Development of Team Records (October 2001 to March 2025) - Stag =====\n",
      "Line 2935: \\subsection{Development of Team Records (October 2001 to March 2025)}\n",
      "Line 2936: \\subsubsection{Stag}\n",
      "Line 2937: \n",
      "Line 2938: % Table Group 1: 50 FREE + 100 FREE\n",
      "Line 2939: \\begin{table}[H]\n",
      "Line 2935: \\subsection{Development of Team Records (October 2001 to March 2025)}\n",
      "Line 2936: \\subsubsection{Stag}\n",
      "Line 2937: \n",
      "Line 2938: % Table Group 1: 50 FREE + 100 FREE\n",
      "Line 2939: \\begin{table}[H]\n",
      "Line 2940: \\centering\n",
      "Line 3354: % ===== END Development of Team Records (October 2001 to March 2025) - Stag =====\n",
      "Line 3355: \n",
      "Line 3356: \\newpage\n",
      "Line 3357: \n",
      "Line 3358: % ===== CMS at UCSD - Athena =====\n",
      "Line 3359: \\subsection{CMS at UCSD}\n"
     ]
    }
   ],
   "source": [
    "# Generate complete LaTeX for all sections\n",
    "def generate_complete_latex():\n",
    "    \"\"\"Generate LaTeX for all sheet/sex combinations with manual editing support\"\"\"\n",
    "    all_latex = []\n",
    "    \n",
    "    # Add file header with summary information\n",
    "    all_latex.append(\"% ===== CMS MEDIA GUIDE - GENERATED LATEX =====\")\n",
    "    all_latex.append(\"% This file contains all swimming and diving tables\")\n",
    "    all_latex.append(\"% Optimized for manual editing and page layout\")\n",
    "    all_latex.append(\"\")\n",
    "    \n",
    "    # Generate summary of sections\n",
    "    all_latex.append(\"% ===== SECTION SUMMARY =====\")\n",
    "    section_count = 0\n",
    "    for sheet in sheet_order:\n",
    "        sheet_data = df[df['SHEET'] == sheet]\n",
    "        if len(sheet_data) == 0:\n",
    "            continue\n",
    "            \n",
    "        available_sexes = sheet_data['SEX'].unique()\n",
    "        for sex in sex_order:\n",
    "            if sex in available_sexes:\n",
    "                section_count += 1\n",
    "                all_latex.append(f\"% {section_count}. {sheet} - {sex}\")\n",
    "    \n",
    "    all_latex.append(f\"% Total sections: {section_count}\")\n",
    "    all_latex.append(\"\")\n",
    "    all_latex.append(\"% ===== END SUMMARY =====\")\n",
    "    all_latex.append(\"\")\n",
    "    \n",
    "    # Generate actual content\n",
    "    for sheet in sheet_order:\n",
    "        sheet_data = df[df['SHEET'] == sheet]\n",
    "        if len(sheet_data) == 0:\n",
    "            continue\n",
    "            \n",
    "        # Get available sexes for this sheet\n",
    "        available_sexes = sheet_data['SEX'].unique()\n",
    "        \n",
    "        for sex in sex_order:\n",
    "            if sex not in available_sexes:\n",
    "                continue\n",
    "                \n",
    "            sex_data = sheet_data[sheet_data['SEX'] == sex]\n",
    "            \n",
    "            # Group by event in order\n",
    "            events_data = []\n",
    "            for event in event_order:\n",
    "                event_data = sex_data[sex_data['EVENT'] == event]\n",
    "                if len(event_data) > 0:\n",
    "                    events_data.append((event, event_data))\n",
    "            \n",
    "            if events_data:  # Only generate if there's data\n",
    "                section_latex = generator.generate_section_latex(sheet, sex, events_data)\n",
    "                all_latex.append(section_latex)\n",
    "                \n",
    "                # Add page break after each section\n",
    "                all_latex.append(\"\\\\newpage\")\n",
    "                all_latex.append(\"\")\n",
    "    \n",
    "    return \"\\n\".join(all_latex)\n",
    "\n",
    "# Generate the complete LaTeX\n",
    "print(\"Generating complete LaTeX...\")\n",
    "complete_latex = generate_complete_latex()\n",
    "\n",
    "# Save to file\n",
    "with open('/home/ben/Desktop/Projects/media_guide/latex/sections/generated_latex.tex', 'w') as f:\n",
    "    f.write(complete_latex)\n",
    "\n",
    "print(f\"Generated LaTeX saved to 'generated_latex.tex'\")\n",
    "print(f\"Total length: {len(complete_latex)} characters\")\n",
    "print(f\"Number of lines: {complete_latex.count(chr(10))}\")\n",
    "\n",
    "# Show preview\n",
    "print(\"\\nPreview (first 15 lines):\")\n",
    "lines = complete_latex.split('\\n')\n",
    "for i, line in enumerate(lines[:15]):\n",
    "    print(f\"{i+1:2d}: {line}\")\n",
    "if len(lines) > 15:\n",
    "    print(f\"... and {len(lines) - 15} more lines\")\n",
    "\n",
    "# Check for the problematic section\n",
    "print(\"\\nChecking for Development of Team Records section:\")\n",
    "dev_section_lines = [i for i, line in enumerate(lines) if \"Development of Team Records\" in line]\n",
    "for line_num in dev_section_lines:\n",
    "    print(f\"Line {line_num+1}: {lines[line_num]}\")\n",
    "    # Show a few lines after this\n",
    "    for j in range(1, 6):\n",
    "        if line_num + j < len(lines):\n",
    "            print(f\"Line {line_num+j+1}: {lines[line_num + j]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "472daa2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating dual meet tables...\n",
      "Found 1016 records for dual meets\n",
      "Sheets: ['CMS at UCSD', 'CMS at Cal Baptist Distance Meet', 'CMS at PP']\n",
      "\n",
      "Processing CMS at UCSD...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'TIME'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/main/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'TIME'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 133\u001b[39m\n\u001b[32m    131\u001b[39m \u001b[38;5;66;03m# Generate the dual meet tables\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mGenerating dual meet tables...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m dual_latex = \u001b[43mgenerate_dual_meet_tables\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[38;5;66;03m# Save to file\u001b[39;00m\n\u001b[32m    136\u001b[39m output_file = \u001b[33m'\u001b[39m\u001b[33m/home/ben/Desktop/Projects/media_guide/latex/sections/gen_dual.tex\u001b[39m\u001b[33m'\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 80\u001b[39m, in \u001b[36mgenerate_dual_meet_tables\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     78\u001b[39m rows = []\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m event_data.iterrows():\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m     time_val = \u001b[38;5;28mstr\u001b[39m(row[\u001b[33m'\u001b[39m\u001b[33mTIME\u001b[39m\u001b[33m'\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m pd.notna(\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mTIME\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     81\u001b[39m     name_val = \u001b[38;5;28mstr\u001b[39m(row[\u001b[33m'\u001b[39m\u001b[33mNAME\u001b[39m\u001b[33m'\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m pd.notna(row[\u001b[33m'\u001b[39m\u001b[33mNAME\u001b[39m\u001b[33m'\u001b[39m]) \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     82\u001b[39m     year_val = \u001b[38;5;28mstr\u001b[39m(row[\u001b[33m'\u001b[39m\u001b[33mYEAR\u001b[39m\u001b[33m'\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m pd.notna(row[\u001b[33m'\u001b[39m\u001b[33mYEAR\u001b[39m\u001b[33m'\u001b[39m]) \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/main/lib/python3.11/site-packages/pandas/core/series.py:1130\u001b[39m, in \u001b[36mSeries.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1127\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[key]\n\u001b[32m   1129\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[32m-> \u001b[39m\u001b[32m1130\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1132\u001b[39m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[32m   1133\u001b[39m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[32m   1134\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/main/lib/python3.11/site-packages/pandas/core/series.py:1246\u001b[39m, in \u001b[36mSeries._get_value\u001b[39m\u001b[34m(self, label, takeable)\u001b[39m\n\u001b[32m   1243\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[label]\n\u001b[32m   1245\u001b[39m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1246\u001b[39m loc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1248\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[32m   1249\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[loc]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/main/lib/python3.11/site-packages/pandas/core/indexes/base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'TIME'"
     ]
    }
   ],
   "source": [
    "# Generate dual meet tables using teamrecordtable macro\n",
    "def generate_dual_meet_tables():\n",
    "    \"\"\"Generate LaTeX for dual meet sheets using teamrecordtable macro in 2-column layout\"\"\"\n",
    "    \n",
    "    # Define the dual meet sheets we want to process\n",
    "    dual_meet_sheets = [\n",
    "        'CMS at UCSD',\n",
    "        'CMS at Cal Baptist Distance Meet', \n",
    "        'CMS at PP'\n",
    "    ]\n",
    "    \n",
    "    # Filter data for these sheets only\n",
    "    dual_data = df[df['SHEET'].isin(dual_meet_sheets)]\n",
    "    \n",
    "    print(f\"Found {len(dual_data)} records for dual meets\")\n",
    "    print(f\"Sheets: {dual_meet_sheets}\")\n",
    "    \n",
    "    latex_parts = []\n",
    "    \n",
    "    # Add header\n",
    "    latex_parts.append(\"% ===== DUAL MEET TABLES =====\")\n",
    "    latex_parts.append(\"% Generated using teamrecordtable macro\")\n",
    "    latex_parts.append(\"\")\n",
    "    \n",
    "    # Process each sheet\n",
    "    for sheet in dual_meet_sheets:\n",
    "        sheet_data = dual_data[dual_data['SHEET'] == sheet]\n",
    "        if len(sheet_data) == 0:\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\nProcessing {sheet}...\")\n",
    "        \n",
    "        # Escape sheet name for LaTeX\n",
    "        escaped_sheet_name = sheet.replace('&', '\\\\&')\n",
    "        latex_parts.append(f\"\\\\subsection{{{escaped_sheet_name}}}\")\n",
    "        latex_parts.append(\"\")\n",
    "        \n",
    "        # Get available sexes for this sheet\n",
    "        available_sexes = sheet_data['SEX'].unique()\n",
    "        \n",
    "        for sex in ['Athena', 'Stag', 'Women', 'Men']:\n",
    "            if sex not in available_sexes:\n",
    "                continue\n",
    "                \n",
    "            sex_data = sheet_data[sheet_data['SEX'] == sex]\n",
    "            \n",
    "            # Escape sex name for LaTeX\n",
    "            escaped_sex_name = sex.replace('&', '\\\\&')\n",
    "            latex_parts.append(f\"\\\\subsubsection{{{escaped_sex_name}}}\")\n",
    "            latex_parts.append(\"\")\n",
    "            \n",
    "            # Group by event in order\n",
    "            events_data = []\n",
    "            for event in event_order:\n",
    "                event_data = sex_data[sex_data['EVENT'] == event]\n",
    "                if len(event_data) > 0:\n",
    "                    # Sort by time if TIME column exists\n",
    "                    if 'TIME' in event_data.columns:\n",
    "                        event_data = event_data.copy()\n",
    "                        event_data['time_seconds'] = event_data['TIME'].apply(\n",
    "                            lambda x: float('inf') if pd.isna(x) else \n",
    "                            (float(x.split(':')[0]) * 60 + float(x.split(':')[1]) if ':' in str(x) else float(x))\n",
    "                        )\n",
    "                        event_data = event_data.sort_values('time_seconds').drop('time_seconds', axis=1)\n",
    "                        event_data = event_data.reset_index(drop=True)\n",
    "                    events_data.append((event, event_data))\n",
    "            \n",
    "            # Group events in pairs for 2-column layout\n",
    "            for i in range(0, len(events_data), 2):\n",
    "                latex_parts.append(\"\\\\begin{table}[H]\")\n",
    "                latex_parts.append(\"\\\\centering\")\n",
    "                \n",
    "                # First event\n",
    "                if i < len(events_data):\n",
    "                    event_name, event_data = events_data[i]\n",
    "                    \n",
    "                    # Generate table rows for teamrecordtable macro\n",
    "                    rows = []\n",
    "                    for _, row in event_data.iterrows():\n",
    "                        time_val = str(row['TIME']) if pd.notna(row['TIME']) else \"\"\n",
    "                        name_val = str(row['NAME']) if pd.notna(row['NAME']) else \"\"\n",
    "                        year_val = str(row['YEAR']) if pd.notna(row['YEAR']) else \"\"\n",
    "                        \n",
    "                        # Escape special LaTeX characters\n",
    "                        time_val = time_val.replace('&', '\\\\&').replace('%', '\\\\%')\n",
    "                        name_val = name_val.replace('&', '\\\\&').replace('%', '\\\\%')\n",
    "                        \n",
    "                        rows.append(f\"    {time_val} & {name_val} & {year_val} \\\\\\\\\")\n",
    "                    \n",
    "                    table_content = \"\\n\".join(rows)\n",
    "                    \n",
    "                    latex_parts.append(\"\\\\begin{minipage}[t]{0.48\\\\textwidth}\")\n",
    "                    latex_parts.append(f\"\\\\teamrecordtable{{{event_name}}}{{\")\n",
    "                    latex_parts.append(table_content)\n",
    "                    latex_parts.append(\"}\")\n",
    "                    latex_parts.append(\"\\\\end{minipage}\\\\hfill\")\n",
    "                \n",
    "                # Second event (if available)\n",
    "                if i + 1 < len(events_data):\n",
    "                    event_name, event_data = events_data[i + 1]\n",
    "                    \n",
    "                    # Generate table rows for teamrecordtable macro\n",
    "                    rows = []\n",
    "                    for _, row in event_data.iterrows():\n",
    "                        time_val = str(row['TIME']) if pd.notna(row['TIME']) else \"\"\n",
    "                        name_val = str(row['NAME']) if pd.notna(row['NAME']) else \"\"\n",
    "                        year_val = str(row['YEAR']) if pd.notna(row['YEAR']) else \"\"\n",
    "                        \n",
    "                        # Escape special LaTeX characters\n",
    "                        time_val = time_val.replace('&', '\\\\&').replace('%', '\\\\%')\n",
    "                        name_val = name_val.replace('&', '\\\\&').replace('%', '\\\\%')\n",
    "                        \n",
    "                        rows.append(f\"    {time_val} & {name_val} & {year_val} \\\\\\\\\")\n",
    "                    \n",
    "                    table_content = \"\\n\".join(rows)\n",
    "                    \n",
    "                    latex_parts.append(\"\\\\begin{minipage}[t]{0.48\\\\textwidth}\")\n",
    "                    latex_parts.append(f\"\\\\teamrecordtable{{{event_name}}}{{\")\n",
    "                    latex_parts.append(table_content)\n",
    "                    latex_parts.append(\"}\")\n",
    "                    latex_parts.append(\"\\\\end{minipage}\")\n",
    "                else:\n",
    "                    # If only one event, close the minipage properly\n",
    "                    latex_parts[-1] = \"\\\\end{minipage}\"  # Remove \\hfill\n",
    "                \n",
    "                latex_parts.append(\"\\\\end{table}\")\n",
    "                latex_parts.append(\"\")\n",
    "    \n",
    "    return \"\\n\".join(latex_parts)\n",
    "\n",
    "# Generate the dual meet tables\n",
    "print(\"Generating dual meet tables...\")\n",
    "dual_latex = generate_dual_meet_tables()\n",
    "\n",
    "# Save to file\n",
    "output_file = '/home/ben/Desktop/Projects/media_guide/latex/sections/gen_dual.tex'\n",
    "with open(output_file, 'w') as f:\n",
    "    f.write(dual_latex)\n",
    "\n",
    "print(f\"Generated dual meet LaTeX saved to 'gen_dual.tex'\")\n",
    "print(f\"Total length: {len(dual_latex)} characters\")\n",
    "print(f\"Number of lines: {dual_latex.count(chr(10))}\")\n",
    "\n",
    "# Show preview\n",
    "print(\"\\nPreview (first 20 lines):\")\n",
    "lines = dual_latex.split('\\n')\n",
    "for i, line in enumerate(lines[:20]):\n",
    "    print(f\"{i+1:2d}: {line}\")\n",
    "if len(lines) > 20:\n",
    "    print(f\"... and {len(lines) - 20} more lines\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbab8f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating dual meet tables with fixed column handling...\n",
      "Found 1016 records for dual meets\n",
      "Sheets: ['CMS at UCSD', 'CMS at Cal Baptist Distance Meet', 'CMS at PP']\n",
      "Available columns: ['SHEET', 'SEX', 'EVENT', ' TIME', 'NAME', 'YEAR', 'TEAM', 'RANK', 'SITE', 'MEET', 'CONTEXT']\n",
      "\n",
      "Processing CMS at UCSD...\n",
      "\n",
      "Processing CMS at Cal Baptist Distance Meet...\n",
      "\n",
      "Processing CMS at PP...\n",
      "Generated dual meet LaTeX saved to 'gen_dual.tex'\n",
      "Total length: 51286 characters\n",
      "Number of lines: 1632\n",
      "\n",
      "Preview (first 20 lines):\n",
      " 1: % ===== DUAL MEET TABLES =====\n",
      " 2: % Generated using teamrecordtable macro\n",
      " 3: \n",
      " 4: \\subsection{CMS at UCSD}\n",
      " 5: \n",
      " 6: \\subsubsection{Athena}\n",
      " 7: \n",
      " 8: \\begin{table}[H]\n",
      " 9: \\centering\n",
      "10: \\begin{minipage}[t]{0.48\\textwidth}\n",
      "11: \\teamrecordtable{50 FREE}{\n",
      "12:     24.45 & Kelly Ngo & 2014 \\\\\n",
      "13:     24.50 & Lorea Gwo & 2014 \\\\\n",
      "14:     24.53 & Ava Sealander & 2019 \\\\\n",
      "15:     24.58 & Kelly Ngo & 2016 \\\\\n",
      "16:     24.64 & Annette Chang & 2023 \\\\\n",
      "17:     24.65 & Kelly Ngo & 2015 \\\\\n",
      "18:     24.66 & Mackenzie Mayfield & 2024 \\\\\n",
      "19:     24.66 & Jocelyn Crawford & 2016 \\\\\n",
      "20:     24.76 & Ally Rudolph & 2023 \\\\\n",
      "... and 1613 more lines\n"
     ]
    }
   ],
   "source": [
    "# Fixed version: Generate dual meet tables using teamrecordtable macro\n",
    "def generate_dual_meet_tables_fixed():\n",
    "    \"\"\"Generate LaTeX for dual meet sheets using teamrecordtable macro in 2-column layout\"\"\"\n",
    "    \n",
    "    # Define the dual meet sheets we want to process\n",
    "    dual_meet_sheets = [\n",
    "        'CMS at UCSD',\n",
    "        'CMS at Cal Baptist Distance Meet', \n",
    "        'CMS at PP'\n",
    "    ]\n",
    "    \n",
    "    # Filter data for these sheets only\n",
    "    dual_data = df[df['SHEET'].isin(dual_meet_sheets)]\n",
    "    \n",
    "    print(f\"Found {len(dual_data)} records for dual meets\")\n",
    "    print(f\"Sheets: {dual_meet_sheets}\")\n",
    "    print(f\"Available columns: {list(dual_data.columns)}\")\n",
    "    \n",
    "    latex_parts = []\n",
    "    \n",
    "    # Add header\n",
    "    latex_parts.append(\"% ===== DUAL MEET TABLES =====\")\n",
    "    latex_parts.append(\"% Generated using teamrecordtable macro\")\n",
    "    latex_parts.append(\"\")\n",
    "    \n",
    "    # Helper function to get column value safely (handles spaces in column names)\n",
    "    def get_column_value(row, column_name):\n",
    "        \"\"\"Get column value with fallback to similar column names\"\"\"\n",
    "        # First try exact match\n",
    "        if column_name in row.index:\n",
    "            return str(row[column_name]) if pd.notna(row[column_name]) else \"\"\n",
    "        \n",
    "        # Try variations with spaces (common issue with CSV imports)\n",
    "        variations = [f\" {column_name}\", f\"{column_name} \", f\" {column_name} \"]\n",
    "        for var in variations:\n",
    "            if var in row.index:\n",
    "                return str(row[var]) if pd.notna(row[var]) else \"\"\n",
    "        \n",
    "        return \"\"\n",
    "    \n",
    "    # Helper function to sort by time\n",
    "    def sort_by_time(data, time_col_name):\n",
    "        \"\"\"Sort data by time column\"\"\"\n",
    "        # Find the actual time column name\n",
    "        time_col = None\n",
    "        if time_col_name in data.columns:\n",
    "            time_col = time_col_name\n",
    "        else:\n",
    "            # Try variations with spaces\n",
    "            variations = [f\" {time_col_name}\", f\"{time_col_name} \", f\" {time_col_name} \"]\n",
    "            for var in variations:\n",
    "                if var in data.columns:\n",
    "                    time_col = var\n",
    "                    break\n",
    "        \n",
    "        if time_col is None:\n",
    "            return data  # No time column found, return unsorted\n",
    "        \n",
    "        data = data.copy()\n",
    "        data['time_seconds'] = data[time_col].apply(\n",
    "            lambda x: float('inf') if pd.isna(x) else \n",
    "            (float(str(x).split(':')[0]) * 60 + float(str(x).split(':')[1]) if ':' in str(x) else float(str(x))) if str(x).replace('.', '').replace(':', '').replace('-', '').isdigit() else float('inf')\n",
    "        )\n",
    "        data = data.sort_values('time_seconds').drop('time_seconds', axis=1)\n",
    "        return data.reset_index(drop=True)\n",
    "    \n",
    "    # Process each sheet\n",
    "    for sheet in dual_meet_sheets:\n",
    "        sheet_data = dual_data[dual_data['SHEET'] == sheet]\n",
    "        if len(sheet_data) == 0:\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\nProcessing {sheet}...\")\n",
    "        \n",
    "        # Escape sheet name for LaTeX\n",
    "        escaped_sheet_name = sheet.replace('&', '\\\\&')\n",
    "        latex_parts.append(f\"\\\\subsection{{{escaped_sheet_name}}}\")\n",
    "        latex_parts.append(\"\")\n",
    "        \n",
    "        # Get available sexes for this sheet\n",
    "        available_sexes = sheet_data['SEX'].unique()\n",
    "        \n",
    "        for sex in ['Athena', 'Stag', 'Women', 'Men']:\n",
    "            if sex not in available_sexes:\n",
    "                continue\n",
    "                \n",
    "            sex_data = sheet_data[sheet_data['SEX'] == sex]\n",
    "            \n",
    "            # Escape sex name for LaTeX\n",
    "            escaped_sex_name = sex.replace('&', '\\\\&')\n",
    "            latex_parts.append(f\"\\\\subsubsection{{{escaped_sex_name}}}\")\n",
    "            latex_parts.append(\"\")\n",
    "            \n",
    "            # Group by event in order\n",
    "            events_data = []\n",
    "            for event in event_order:\n",
    "                event_data = sex_data[sex_data['EVENT'] == event]\n",
    "                if len(event_data) > 0:\n",
    "                    # Sort by time if TIME column exists\n",
    "                    event_data = sort_by_time(event_data, 'TIME')\n",
    "                    events_data.append((event, event_data))\n",
    "            \n",
    "            # Group events in pairs for 2-column layout\n",
    "            for i in range(0, len(events_data), 2):\n",
    "                latex_parts.append(\"\\\\begin{table}[H]\")\n",
    "                latex_parts.append(\"\\\\centering\")\n",
    "                \n",
    "                # First event\n",
    "                if i < len(events_data):\n",
    "                    event_name, event_data = events_data[i]\n",
    "                    \n",
    "                    # Generate table rows for teamrecordtable macro\n",
    "                    rows = []\n",
    "                    for _, row in event_data.iterrows():\n",
    "                        time_val = get_column_value(row, 'TIME')\n",
    "                        name_val = get_column_value(row, 'NAME')\n",
    "                        year_val = get_column_value(row, 'YEAR')\n",
    "                        \n",
    "                        # Escape special LaTeX characters\n",
    "                        time_val = time_val.replace('&', '\\\\&').replace('%', '\\\\%').replace('$', '\\\\$')\n",
    "                        name_val = name_val.replace('&', '\\\\&').replace('%', '\\\\%').replace('$', '\\\\$')\n",
    "                        \n",
    "                        rows.append(f\"    {time_val} & {name_val} & {year_val} \\\\\\\\\")\n",
    "                    \n",
    "                    table_content = \"\\n\".join(rows)\n",
    "                    \n",
    "                    latex_parts.append(\"\\\\begin{minipage}[t]{0.48\\\\textwidth}\")\n",
    "                    latex_parts.append(f\"\\\\teamrecordtable{{{event_name}}}{{\")\n",
    "                    latex_parts.append(table_content)\n",
    "                    latex_parts.append(\"}\")\n",
    "                    latex_parts.append(\"\\\\end{minipage}\\\\hfill\")\n",
    "                \n",
    "                # Second event (if available)\n",
    "                if i + 1 < len(events_data):\n",
    "                    event_name, event_data = events_data[i + 1]\n",
    "                    \n",
    "                    # Generate table rows for teamrecordtable macro\n",
    "                    rows = []\n",
    "                    for _, row in event_data.iterrows():\n",
    "                        time_val = get_column_value(row, 'TIME')\n",
    "                        name_val = get_column_value(row, 'NAME')\n",
    "                        year_val = get_column_value(row, 'YEAR')\n",
    "                        \n",
    "                        # Escape special LaTeX characters\n",
    "                        time_val = time_val.replace('&', '\\\\&').replace('%', '\\\\%').replace('$', '\\\\$')\n",
    "                        name_val = name_val.replace('&', '\\\\&').replace('%', '\\\\%').replace('$', '\\\\$')\n",
    "                        \n",
    "                        rows.append(f\"    {time_val} & {name_val} & {year_val} \\\\\\\\\")\n",
    "                    \n",
    "                    table_content = \"\\n\".join(rows)\n",
    "                    \n",
    "                    latex_parts.append(\"\\\\begin{minipage}[t]{0.48\\\\textwidth}\")\n",
    "                    latex_parts.append(f\"\\\\teamrecordtable{{{event_name}}}{{\")\n",
    "                    latex_parts.append(table_content)\n",
    "                    latex_parts.append(\"}\")\n",
    "                    latex_parts.append(\"\\\\end{minipage}\")\n",
    "                else:\n",
    "                    # If only one event, close the minipage properly\n",
    "                    latex_parts[-1] = \"\\\\end{minipage}\"  # Remove \\hfill\n",
    "                \n",
    "                latex_parts.append(\"\\\\end{table}\")\n",
    "                latex_parts.append(\"\")\n",
    "    \n",
    "    return \"\\n\".join(latex_parts)\n",
    "\n",
    "# Generate the dual meet tables with fixed code\n",
    "print(\"Generating dual meet tables with fixed column handling...\")\n",
    "dual_latex = generate_dual_meet_tables_fixed()\n",
    "\n",
    "# Save to file\n",
    "output_file = '/home/ben/Desktop/Projects/media_guide/latex/sections/gen_dual.tex'\n",
    "with open(output_file, 'w') as f:\n",
    "    f.write(dual_latex)\n",
    "\n",
    "print(f\"Generated dual meet LaTeX saved to 'gen_dual.tex'\")\n",
    "print(f\"Total length: {len(dual_latex)} characters\")\n",
    "print(f\"Number of lines: {dual_latex.count(chr(10))}\")\n",
    "\n",
    "# Show preview\n",
    "print(\"\\nPreview (first 20 lines):\")\n",
    "lines = dual_latex.split('\\n')\n",
    "for i, line in enumerate(lines[:20]):\n",
    "    print(f\"{i+1:2d}: {line}\")\n",
    "if len(lines) > 20:\n",
    "    print(f\"... and {len(lines) - 20} more lines\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2caf0018",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
